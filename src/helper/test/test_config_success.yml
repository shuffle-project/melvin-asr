# config_dev.yml
# This file is used to configure the service locally for development

log_level: DEBUG 
host: "localhost"
api_keys: 
  - "shuffle2024"
  - "api_key_1"
  - "api_key_2"

# Transcription Configuration, defaults set for websocket_stream and rest_runner
transcription_default:
  # all valid faster-whisper transcription settings are allowed here
  # see "src/helper/transcription_settings.py"
  vad_filter: True
  condition_on_previous_text: False
  word_timestamps: False
  language: "en"

# Runner Configuration
# The max. count of runners for rest_runner is 10
# The max. count of runners for stream_runner is 1

websocket_stream:
  cpu:
    active: True
    model: tiny
    cpu_threads: 4
    worker_seats: 1

  cuda:
    active: False
    model: tiny
    device_index: 0
    worker_seats: 1

rest_runner:
      # device: "cpu" or "cuda"
  -   device: cpu
      # model: tiny, small, medium, large, large-v3 (https://huggingface.co/Systran)
      models: 
      - tiny
      - large-v3
      # compute_type:"int8" (cpu), "float16" (cuda), "int8_float16" (cuda)
      compute_type: int8
      # device_index: Only for Cuda, device_index is the index of the GPU, see CLI "nvidia-smi"
      device_index: 0
      # num_workers: Only for CPU, in our setup it should always be 1 or 2
      num_workers: 1
      # cpu_threads: Only for CPU, depends on the type of CPU, try out different values to find the best one
        # for 128 cores, use 8/16
        # for 64 cores, use 4/8
        # for 32 cores, use 2/4
      cpu_threads: 4
